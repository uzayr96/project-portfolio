{"title":"Introduction","markdown":{"yaml":{"title":"Introduction"},"headingText":"Importing dataset and Preprocessing","containsRefs":false,"markdown":"\n\n\n\nLending club is a company which brings borrowers and investers together, altering the way people acquire loans. Lending club, in this dataset, complete data for all the loans provided from 2007 to 2015 with more than 22 million records including the status of loan i.e. whether a loan was paid on time or defaulted etc. The data can be found on [this link](https://www.kaggle.com/wendykan/lending-club-loan-data). \n\n\n\nAs the data is big, I have added a code to get the sample dataset incase if the code becomes slow or the kernel crashes.\n\n## Brief Exploratory Data Analysis\n\nThis variable will be used as target variable in our logistic regression model. This variable has class imbalance problem. We can deal with this problem with the help of oversampling or undersampling.\n\nGrade is the rating from agency which explains the creditworthiness of the borrower. Grade A is the highest rating which means that the borrower is more likely to repay the loan on time whereas grade G is the lower rating, suggesting the lower creditworthiness of the borrower.\n\nThe plot above clearly shows that people with higher credit ratings have paid their loans. The percentage of default increased as the rating decreased.\n\n## Extracting numeric values from columns\n\nLooking at the first 5 rows, we can see that some columns that are actually numeric, like emp_length, term, subgrade etc, are recorded as strings due to alphabets and + sign. We will simply extract numeric values from that column and store it new variable.\n\n## Getting Dates\n\nWe have few strings that are actually date, so we will convert all those columns to date type.\n\nNow we will get the difference in months from earliest credit line date till now.\n\n## Dropping few string columns\n\n## Extracting the month and year into different columns\nI have added this code in comments incase the we extract months and years from the date columns.\n\n## Removing Date columns\n\n#### EDA after creation of good/bad variable\n\nIt seems that the number of default increases as the interest rate increases, which seems obvious as people have to pay more.\n\n### Get dummies\n\n## Missing Values\nLets locate the missing values and the percentage so that we can decide whether to impute the missing values or drop the entire column. \n\nWe have few columns with more than 75 % of the missing values, we cannot impute values without any information. I will remove all columns with more than 75% of the missing values\n\n# Data Transformation - Weight of Evidence\nI will use weight of evidence method to preprocess the data and select the variables for the logistic regression model.\nWeight of evidence will show us how much a particular category is contributing to a particular loan status. Higher weight of evidence will suggest more chances of full repayment of loan and vice versa.\n\n## Categorical Columns\n\n### Grade\n\nSo the lower the weight of evidence the higher the risk of default. Looking at the graph above, we can clearly see that higher credit rating results in lower chances of default. In this variable, I will keep all dummy variables except grade G as the number of observations and weight of evidence is low.\n\n### Home OwnerShip\n\nThis category is slightly more complicated. The number of observation for other, none, and any cateogory is low but the weight of evidence is high for ANY.\n\n### Address State\n\nThis is a bit more complicated to preprocess, as we can see that IA state has only 14 observations and the weight of evidence is extremely low as compare to other states. In order to combine similar categories, we will take into account the number of observations and weight of evidence.\n\n### Purpose\n\nThis category also has the same problem. Again we will perform similar operation to reduce the number of dummy variables\n\nThere is alot of difference in the weight of evidence of each category so we will keep all these categories.\n\n### Initial List Status\n\nWe will keep both of these categories\n\n## Numeric columns\n\n### Term\n\n### Employment Length\n\n### Month Difference from Issuedate\n\n### Interest Rate\n\nLooking at the above graph, we can see that as the interest rate is increasing, the chances of default is also increasing.\n\n### Funded Amount\n\n### Annual Income\n\nAbove graph suggests that higher annual income results in lower chances of default. The first category has extremely low number of observations so we will ignore this category.\n\n### DTI\nThis column has missing values and skewness related issues. In order to preprocess this column, I will remove the observations with missing values and add all the extreme values in one category.\n\n### Total Acc\n\n### Account now Delinq\n\n# Modeling\nI would remove the categories with lowers weight of evidence in each column. \n\n### PD (Probability of Default)\n\n#### Summary of Logistic Regression\n\n### Sklearn\n\n#### Logistic Regression\n\n#### Prediction\n\nSo we know that our model is not just randomly predicting the target variable. I will use other models with default parameters to compare the result with logistic regression model\n\n### Classification Report\n\n### Gini Coefficient\n\n### Roc Curve\n\n#### Predict on the entire dataset\n\nWith other machine learning models like xgboost or random forest and class balancing, we can achieve higher AUC. \n","srcMarkdownNoYaml":"\n\n\n\nLending club is a company which brings borrowers and investers together, altering the way people acquire loans. Lending club, in this dataset, complete data for all the loans provided from 2007 to 2015 with more than 22 million records including the status of loan i.e. whether a loan was paid on time or defaulted etc. The data can be found on [this link](https://www.kaggle.com/wendykan/lending-club-loan-data). \n\n\n\n# Importing dataset and Preprocessing\nAs the data is big, I have added a code to get the sample dataset incase if the code becomes slow or the kernel crashes.\n\n## Brief Exploratory Data Analysis\n\nThis variable will be used as target variable in our logistic regression model. This variable has class imbalance problem. We can deal with this problem with the help of oversampling or undersampling.\n\nGrade is the rating from agency which explains the creditworthiness of the borrower. Grade A is the highest rating which means that the borrower is more likely to repay the loan on time whereas grade G is the lower rating, suggesting the lower creditworthiness of the borrower.\n\nThe plot above clearly shows that people with higher credit ratings have paid their loans. The percentage of default increased as the rating decreased.\n\n## Extracting numeric values from columns\n\nLooking at the first 5 rows, we can see that some columns that are actually numeric, like emp_length, term, subgrade etc, are recorded as strings due to alphabets and + sign. We will simply extract numeric values from that column and store it new variable.\n\n## Getting Dates\n\nWe have few strings that are actually date, so we will convert all those columns to date type.\n\nNow we will get the difference in months from earliest credit line date till now.\n\n## Dropping few string columns\n\n## Extracting the month and year into different columns\nI have added this code in comments incase the we extract months and years from the date columns.\n\n## Removing Date columns\n\n#### EDA after creation of good/bad variable\n\nIt seems that the number of default increases as the interest rate increases, which seems obvious as people have to pay more.\n\n### Get dummies\n\n## Missing Values\nLets locate the missing values and the percentage so that we can decide whether to impute the missing values or drop the entire column. \n\nWe have few columns with more than 75 % of the missing values, we cannot impute values without any information. I will remove all columns with more than 75% of the missing values\n\n# Data Transformation - Weight of Evidence\nI will use weight of evidence method to preprocess the data and select the variables for the logistic regression model.\nWeight of evidence will show us how much a particular category is contributing to a particular loan status. Higher weight of evidence will suggest more chances of full repayment of loan and vice versa.\n\n## Categorical Columns\n\n### Grade\n\nSo the lower the weight of evidence the higher the risk of default. Looking at the graph above, we can clearly see that higher credit rating results in lower chances of default. In this variable, I will keep all dummy variables except grade G as the number of observations and weight of evidence is low.\n\n### Home OwnerShip\n\nThis category is slightly more complicated. The number of observation for other, none, and any cateogory is low but the weight of evidence is high for ANY.\n\n### Address State\n\nThis is a bit more complicated to preprocess, as we can see that IA state has only 14 observations and the weight of evidence is extremely low as compare to other states. In order to combine similar categories, we will take into account the number of observations and weight of evidence.\n\n### Purpose\n\nThis category also has the same problem. Again we will perform similar operation to reduce the number of dummy variables\n\nThere is alot of difference in the weight of evidence of each category so we will keep all these categories.\n\n### Initial List Status\n\nWe will keep both of these categories\n\n## Numeric columns\n\n### Term\n\n### Employment Length\n\n### Month Difference from Issuedate\n\n### Interest Rate\n\nLooking at the above graph, we can see that as the interest rate is increasing, the chances of default is also increasing.\n\n### Funded Amount\n\n### Annual Income\n\nAbove graph suggests that higher annual income results in lower chances of default. The first category has extremely low number of observations so we will ignore this category.\n\n### DTI\nThis column has missing values and skewness related issues. In order to preprocess this column, I will remove the observations with missing values and add all the extreme values in one category.\n\n### Total Acc\n\n### Account now Delinq\n\n# Modeling\nI would remove the categories with lowers weight of evidence in each column. \n\n### PD (Probability of Default)\n\n#### Summary of Logistic Regression\n\n### Sklearn\n\n#### Logistic Regression\n\n#### Prediction\n\nSo we know that our model is not just randomly predicting the target variable. I will use other models with default parameters to compare the result with logistic regression model\n\n### Classification Report\n\n### Gini Coefficient\n\n### Roc Curve\n\n#### Predict on the entire dataset\n\nWith other machine learning models like xgboost or random forest and class balancing, we can achieve higher AUC. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true,"link-external-filter":"^(?:http:|https:)\\/\\/www\\.quarto\\.org\\/custom"},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":false,"css":["custom.css"],"output-file":"Credit Risk Modelling.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.43","smooth-scroll":true,"page-layout":"article","theme":["cosmo","custom.scss"],"fontsize":"1.2rem","linestretch":1.7,"title":"Introduction"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}